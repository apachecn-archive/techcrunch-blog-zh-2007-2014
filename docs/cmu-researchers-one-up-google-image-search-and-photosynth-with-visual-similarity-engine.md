# CMU 研究人员用视觉相似性引擎领先谷歌图片搜索和图片合成

> 原文：<https://web.archive.org/web/https://techcrunch.com/2011/12/06/cmu-researchers-one-up-google-image-search-and-photosynth-with-visual-similarity-engine/>

如今，搜索真的是一个极其服务密集型的过程。以前，搜索某样东西意味着你必须用手翻遍抽屉或文件夹，用眼睛检查，而现在它只意味着产生一个查询，并允许云服务的巨大计算引擎并行发挥作用，筛选数 Pb 的数据，并立即向你展示你的结果，就像大盘子上的小吃一样排序和排列。至少可以说，我们被宠坏了。

然而，让计算机盲目地比较 1 和 0 是不够的；当人类搜索时，他们搜索得很聪明。我们已经看到在这方面的能力有了令人难以置信的飞跃，在视觉搜索领域，我们已经看到了一些有趣和实用的技术，分别是和谷歌的[图片搜索](https://web.archive.org/web/20230330153141/https://techcrunch.com/2011/06/14/google-search-by-image-use-a-snapshot-as-your-search-query/)功能。现在，CMU 的一些研究人员在工具教育方面又迈出了一步。他们的工作在亚洲 SIGGRAPH】展出，更加接近人类的视觉认知，尽管在这方面还有很长的路要走。

当比较图像的相似性时，挑战在于如何确定图像中使其独特的部分。对我们来说，这简直是小菜一碟:我们在蹒跚学步时就学习了视觉辨别的基础知识，并有几十年的实践经验。另一方面，计算机视觉没有这样的生物库可以利用，必须通过算法来工作。

![](img/fda918955f6478bd403145b24fd0e3ba.png "header")

为此，卡内基梅隆大学的研究人员确定了一种比较图像的有趣方式。他们没有将一幅给定的图像与其他图像进行面对面的比较，也没有试图确定相似度，而是将问题反过来。他们将目标图像与大量随机图像进行比较，并记录下它与目标图像最大的不同之处。如果另一幅图像在相似的方面有所不同，那么它很可能与第一幅图像相似。很巧妙，不是吗？

结果不言自明:它们不仅像谷歌的搜索工具一样，能够找到形状相似的图像，或者像 Photosynth 一样，能够找到颜色或角度不同的同一物体或位置的图像，而且它们能够可靠地匹配图像的非常不同的版本，如草图、绘画或完全不同季节的图像等等。

他们的视频对此做了很好的解释:

【YouTube http://www.youtube.com/watch?feature = player _ embedded & v = PY _ _ fo4o 67 I w = 640]

本质上，它是一个更像人类的图像比较工具:不是识别一个场景与其他场景的相似之处，而是识别它与世界上其他事物的不同之处。它能识别圣彼得教堂的圆顶，无论是夏天还是冬天，圆珠笔还是照片。

自然有局限性。这个过程不是很高效，而且非常占用 CPU 资源；虽然谷歌可能会在半秒钟内将相当相似的图像返回给你，但 CMU 的方法需要更长的时间，因为它必须筛选无数的图像，并进行复杂的基于区域的比较。但是结果似乎更加精确和可靠，而且计算时间只会减少。

接下来会发生什么？这项研究几乎肯定会继续下去，因为这是一个热门领域，我不会惊讶地看到这些人被其中一个主要公司(谷歌、微软、Flickr)抢购，试图在视觉搜索方面超过其他人。**更新**:谷歌实际上是该项目的资助者之一，尽管以什么身份和级别没有透露。

研究小组由 Abhinav Shrivastava、Tomasz Malisiewicz、Abhinav Gupta 和领导该项目的 Alexei A. Efros 组成。[全文可以在这里下载(PDF)](https://web.archive.org/web/20230330153141/http://graphics.cs.cmu.edu/projects/crossDomainMatching/abhinav-sa11.pdf) 如果你感兴趣，在项目现场还有一些补充信息和视频。