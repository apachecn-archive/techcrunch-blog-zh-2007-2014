<html>
<head>
<title>CMU Researchers One-Up Google Image Search And Photosynth With Visual Similarity Engine | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CMU研究人员用视觉相似性引擎领先谷歌图片搜索和图片合成</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2011/12/06/cmu-researchers-one-up-google-image-search-and-photosynth-with-visual-similarity-engine/">https://web.archive.org/web/https://techcrunch.com/2011/12/06/cmu-researchers-one-up-google-image-search-and-photosynth-with-visual-similarity-engine/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">如今，搜索真的是一个极其服务密集型的过程。以前，搜索某样东西意味着你必须用手翻遍抽屉或文件夹，用眼睛检查，而现在它只意味着产生一个查询，并允许云服务的巨大计算引擎并行发挥作用，筛选数Pb的数据，并立即向你展示你的结果，就像大盘子上的小吃一样排序和排列。至少可以说，我们被宠坏了。</p>
<p class="translated">然而，让计算机盲目地比较1和0是不够的；当人类搜索时，他们搜索得很聪明。我们已经看到在这方面的能力有了令人难以置信的飞跃，在视觉搜索领域，我们已经看到了一些有趣和实用的技术，分别是<a href="https://web.archive.org/web/20230330153141/https://techcrunch.com/tag/photosynth/"/>和谷歌的<a href="https://web.archive.org/web/20230330153141/https://techcrunch.com/2011/06/14/google-search-by-image-use-a-snapshot-as-your-search-query/">图片搜索</a>功能。现在，CMU的一些研究人员在工具教育方面又迈出了一步。他们的工作在亚洲SIGGRAPH】展出，更加接近人类的视觉认知，尽管在这方面还有很长的路要走。</p>
<p class="translated">当比较图像的相似性时，挑战在于如何确定图像中使其独特的部分。对我们来说，这简直是小菜一碟:我们在蹒跚学步时就学习了视觉辨别的基础知识，并有几十年的实践经验。另一方面，计算机视觉没有这样的生物库可以利用，必须通过算法来工作。</p>
<p class="translated"><img decoding="async" src="../Images/fda918955f6478bd403145b24fd0e3ba.png" alt="" title="header" class="aligncenter size-full wp-image-464418" srcset="https://web.archive.org/web/20230330153141im_/https://techcrunch.com/wp-content/uploads/2011/12/header.jpg 640w, https://web.archive.org/web/20230330153141im_/https://techcrunch.com/wp-content/uploads/2011/12/header.jpg?resize=150,76 150w, https://web.archive.org/web/20230330153141im_/https://techcrunch.com/wp-content/uploads/2011/12/header.jpg?resize=300,151 300w, https://web.archive.org/web/20230330153141im_/https://techcrunch.com/wp-content/uploads/2011/12/header.jpg?resize=50,25 50w" sizes="(max-width: 640px) 100vw, 640px" data-original-src="https://web.archive.org/web/20230330153141im_/https://techcrunch.com/wp-content/uploads/2011/12/header.jpg"/></p>
<p class="translated">为此，卡内基梅隆大学的研究人员确定了一种比较图像的有趣方式。他们没有将一幅给定的图像与其他图像进行面对面的比较，也没有试图确定相似度，而是将问题反过来。他们将目标图像与大量随机图像进行比较，并记录下它与目标图像最大的不同之处。如果另一幅图像在相似的方面有所不同，那么它很可能与第一幅图像相似。很巧妙，不是吗？</p>
<p class="translated">结果不言自明:它们不仅像谷歌的搜索工具一样，能够找到形状相似的图像，或者像Photosynth一样，能够找到颜色或角度不同的同一物体或位置的图像，而且它们能够可靠地匹配图像的非常不同的版本，如草图、绘画或完全不同季节的图像等等。</p>
<p class="translated">他们的视频对此做了很好的解释:</p>
<p class="translated">【YouTube http://www.youtube.com/watch?feature = player _ embedded &amp; v = PY _ _ fo4o 67 I w = 640]</p>
<p class="translated">本质上，它是一个更像人类的图像比较工具:不是识别一个场景与其他场景的相似之处，而是识别它与世界上其他事物的不同之处。它能识别圣彼得教堂的圆顶，无论是夏天还是冬天，圆珠笔还是照片。</p>
<p class="translated">自然有局限性。这个过程不是很高效，而且非常占用CPU资源；虽然谷歌可能会在半秒钟内将相当相似的图像返回给你，但CMU的方法需要更长的时间，因为它必须筛选无数的图像，并进行复杂的基于区域的比较。但是结果似乎更加精确和可靠，而且计算时间只会减少。</p>
<p class="translated">接下来会发生什么？这项研究几乎肯定会继续下去，因为这是一个热门领域，我不会惊讶地看到这些人被其中一个主要公司(谷歌、微软、Flickr)抢购，试图在视觉搜索方面超过其他人。<strong>更新</strong>:谷歌实际上是该项目的资助者之一，尽管以什么身份和级别没有透露。</p>
<p class="translated">研究小组由Abhinav Shrivastava、Tomasz Malisiewicz、Abhinav Gupta和领导该项目的Alexei A. Efros组成。<a href="https://web.archive.org/web/20230330153141/http://graphics.cs.cmu.edu/projects/crossDomainMatching/abhinav-sa11.pdf">全文可以在这里下载(PDF) </a>如果你感兴趣，在项目现场还有一些补充信息和视频<a href="https://web.archive.org/web/20230330153141/http://graphics.cs.cmu.edu/projects/crossDomainMatching/"/>。</p>
			</div>

			</div>    
</body>
</html>