# Liveplace 照片般逼真的 3D 世界和 OTOY 渲染引擎背后的真相 

> 原文：<https://web.archive.org/web/https://techcrunch.com/2008/08/20/the-truth-behind-liveplaces-photo-realistic-3d-world-and-otoys-rendering-engine/>

[![](img/bdf37fe939b1c4b986106db2fb4793db.png)](https://web.archive.org/web/20230215155927/http://www.crunchbase.com/company/otoy)

上周，我们发布了一个[视频](https://web.archive.org/web/20230215155927/https://techcrunch.com/2008/08/11/liveplace-to-launch-photo-realistic-virtual-world-rendered-in-the-cloud/)，展示了 LivePlace，一个拥有难以置信的大量细节的 3D 世界。其背后令人印象深刻的技术被称为 OTOY，这是一个流媒体平台，允许开发人员在“云中”生成电影质量的渲染，然后可以传输到性能更低的计算机甚至手机上。想了解更多关于 OTOY 的信息，请看我们的介绍文章[这里](https://web.archive.org/web/20230215155927/https://techcrunch.com/2008/07/09/otoy-developing-server-side-3d-rendering-technology/)。

该视频在 LivePlace.com 向公众开放，旁边还有模糊的标题“直播还是虚拟直播？”但显然没人会发现它。我们发布帖子后不久，LivePlace 就从服务器上删除了这段视频。拥有 LivePlace 的 MySpace 背后的企业家布拉德·格林斯潘(Brad Greenspan)说，该网站从来就不打算让公众看到，他解释说，这是为了内部模型、病毒视频和“类似于搞笑或死亡剧集的东西”这种解释并不适合我，但我们不太可能从格林斯潘那里得到任何更实质性的东西。

[http://blip.tv/play/AcjrSou8cA 电视台]

那么，那个 3D 虚拟世界是什么——它是假的吗？

OTOY 的创始人 Jules Urbach 解释说，虽然他不能评论 Liveplace 正在做什么(或者他们为什么发布视频)，但视频中运行在渲染引擎上的虚拟世界正在路上。他表示，这段视频并不代表他的系统的功能(自视频拍摄以来，该系统的功能实际上已经有所改善)，实际上只是由 Liveplace 拼接在一起的一些随机片段:

> “该材料中 14 分钟的实时渲染以 240 kpbs 的速度实时传输到 Treo 700。这是在 2007 年 3 月捕获的，服务器运行 ATI RX 1900 GPU。从那以后，技术有了很大的进步(就像我们现在运行的硬件一样)。我们从来没有打算向公众展示其中的任何部分，直到我们可以包括体素渲染和基于 Lightstage 的角色。我想任何喜欢他们所看到的东西的人，都会发现最终的项目更加令人印象深刻。
> 
> 我们上个月在 AMD 的 Ruby 演示上所做工作的全部目标是展示从这一代 GPU 开始，离线和实时工作的质量是相同的。本月接下来的演示只是介绍 Lightstage，以及它如何让角色(或任何 CG 对象)在实时环境中看起来 100%真实。
> 
> 直到今年晚些时候，在一个关于为 OTOY 开发的服务器端平台的进一步声明之后，这些技术将被应用到的虚拟世界才被讨论。
> 
> 我们与编辑或泄露这个视频没有任何关系，除了 OTOY 技术之外，我们不能对任何事情发表评论，因为这个项目仍然在 NDA 之下。"

除了在视频中看到的缺乏一致性，读者还担心它可能包含从其他艺术家那里盗版的材料。该视频以一个简短的汽车剪辑开始，显然是从艺术家的作品集中截取的，最初是几年前创作的。事实证明，这些片段是旧的，但朱尔斯·乌尔巴赫解释说，这位艺术家现在是 OTOY 团队的一员:

> “在过去的 3 年里，JJ 一直与 OTOY/JulesWorld 在我们几乎所有的主要项目上进行合作(其中一些项目仍由 NDA 负责)。我非常自豪地把他视为一个伟大的朋友和合作伙伴。
> 
> JJ 的工作室，BLR，总是在我们的客户让我们放上我们的标志的所有视频上得到适当的认可，无论是实时项目还是线性 VFX 工作。你可以在几周前 Techcrunch 上的实时变形金刚 OTOY 剪辑上看到 BLR 的标志(最初来自每日综艺)，你还会在 11 月份以我们的工作为主题的平面广告活动中再次看到它。
> 
> 注意:你在 BCN 街头场景最开始看到的大众甲壳虫是 JJ 的第一个 CG 模型之一，是他的“宝贝”。它几乎出现在我们一起做的所有事情中——从我们为派拉蒙做的“大黄蜂”变形金刚广告，到我们最近为 AMD 做的 Ruby voxel 演示(你可以在街道的右侧找到它)。这也是上个月 OTOY 上 TechCrunch 文章中的[图像之一](https://web.archive.org/web/20230215155927/https://techcrunch.com/wp-content/uploads/2008/07/otoy15.png)(在 512 Mb R770 上实时渲染，预体素渲染器)。

那么底线是什么？LivePlace 似乎与提供的视频或描述的城市没有任何关系，一开始就不应该发布这些镜头。**其背后令人印象深刻的 OTOY 技术是真实的，但我们必须等待，看看哪些产品将利用它**。

以下是朱尔斯提供的更多技术细节:
T5

> –我们以多种方式处理体素数据，包括几何图(参见我们的 Siggraph 或冰岛演示，其中我们展示了这种方法应用于 Ligthstage 5 结构光数据，由安德鲁·琼斯 ICT/Graphics 实验室提供)
> 
> –来自 BCN 和红宝石城场景的数据集每个体素包含多达 64 个数据层，包括漫反射率、菲涅耳反射率值、辐照度数据、UV 坐标(多达 8 组)、法线，对于静态场景，还包括来自多达 252 个均匀分布的视点的 1-20 次光反射的查找向量(需要注意的是，该数据始终是 100%可选的，因为当体素接近且反射精度比速度更重要时，光线投射器可以在程序上做到这一点；但是，使用缓存的反射率数据，当场景没有变化时，您可能会看到场景以 100-1000 fps 的速度渲染。
> 
> –关于光线跟踪与光栅化的说明:使用 GPU tessellator 将 Fincher 的 Bug Snuff 演示中的树干放大到 2800 万个多边形，结果比渲染该对象的 2800 万个体素点云更快。因此，在大约 1 亿个多边形时，体素变得比光栅化快是有一个阈值的。至少在我们的引擎中，在 R7xx GPUs 上，使用 1280×720 的全精确光线投射。在这一点之下，使用 GPU tessellator 的传统光栅化对于单个视口来说似乎更快。
> 
> –在 R770 上，该引擎可以在约 1/200 秒内将一百万多边形网格转换为体素数据(在 R600 和 8800 GTX 上为 60 fps)。这对于烘焙在 GPU 上一次性或偶尔生成的密集静态场景非常有用。这就是为什么有些 OTOY 演示要求 GPU tessellator 看起来正确。
> 
> –OTOY 中的硬阴影是使用光栅化完成的，直到我们在 5 月份获得 R770。现在，硬阴影，像反射，可以使用光线投射来计算，尽管阴影掩膜仍然非常有用，使用体素数据的光线投射仍然会给你带来走样。
> 
> –我们可以将光线投射器与程序生成的数据(柏林生成的地形或云、基于样条的对象等)一起使用。).在 Jon Peddie 的 Siggraph 活动中，我们展示了实时应用于 Ruby street 场景的变形。它是独立于分辨率的，就像一个闪光矢量对象，所以你可以无限接近它而没有阶梯效果，同样，阴影投射也会以同样的方式工作。
> 
> –体素数据被分组为大致相当于“三角形批次”(也可以索引到每个对象或每个材料组)。这使我们能够以与传统多边形网格非常相似的方式处理体素数据的子集。
> 
> –2007 年 3 月“Treo”视频中的反射大约是我们现在在 R770/R700 上用于 Ruby 演示的光线投射的 1/1000 精确/快速。
> 
> –一个 R770 GPU 可以以“Treo”视频中显示的质量和大小渲染大约 100 多个视窗。当场景完全基于体素时，同步视口的数量不如所有视口的总渲染面积重要。
> 
> –服务器端渲染系统目前由使用 8 个 R770 GPU(8 Gb VRAM，每箱 1.5 Kw 功率)的系统组成。